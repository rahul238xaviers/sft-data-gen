# Example environment variables for sft-data-gen
OLLAMA_API_KEY=your_api_key_here
OLLAMA_URL=http://localhost:11434
TEACHER_MODEL=qwen2.5:72b-instruct
AUDITOR_MODEL=deepseek-r1:70b
REDIS_URL=redis://localhost:6379/0
MAX_LLM_CONCURRENCY=8
USE_SINGLE_CALL=1
USE_BATCHING=0
BATCH_SIZE=4
AUDIT_SAMPLE_RATE=0.05
CACHE_BACKEND=disk
# Optional: override prompts file for local development. Point this to your local prompt file (do NOT commit private prompts)
# Example: SFT_PROMPTS_PATH=config/prompt.local.json
SFT_PROMPTS_PATH=config/prompts.example.json
DATASET_PATH=data/processed/your-dataset.train.jsonl
MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
BASE_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct
TEST_PROMPT=What is life insurance?

# Deployment configuration (for deploy_model.ipynb)
# Set your custom model name (do NOT use production names in this file)
OUTPUT_MODEL_NAME=my-finetuned-model
QUANTIZATION=Q4_K_M

# Training hyperparameters for supervised fine-tuning (editable)
OUTPUT_DIR=./results
PER_DEVICE_TRAIN_BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=8
NUM_TRAIN_EPOCHS=3
LEARNING_RATE=0.0002
FP16=True
LOGGING_STEPS=10
SAVE_STEPS=100
SAVE_TOTAL_LIMIT=2
REPORT_TO=none
DATALOADER_PIN_MEMORY=False
REMOVE_UNUSED_COLUMNS=False
OPTIMIZER=paged_adamw_8bit
